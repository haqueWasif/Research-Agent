# ğŸ“š Research Content Generator

A sophisticated multi-agent AI system that generates high-quality research papers, essays, technical reports, and other academic content using advanced prompt engineering and LLM-powered content generation.

## ğŸ¯ Overview

**Research Content Generator** is a professional-grade application built with Streamlit that leverages a two-agent architecture to produce publication-ready research content:

- **Agent 1 (Prompt Engineering Agent)**: Uses an LLM to dynamically generate optimized prompts based on user requirements
- **Agent 2 (Research Generator Agent)**: Generates high-quality research content using the engineered prompts

The system provides a clean, user-focused interface that hides all backend complexity, allowing users to focus on what matters: specifying their needs and receiving polished output.

## ğŸ—ï¸ Architecture

### Two-Agent System

```
User Input
    â†“
[Agent 1: Prompt Engineering]
    â€¢ Analyzes user preferences
    â€¢ Generates optimized prompts
    â†“
[Agent 2: Research Generation]
    â€¢ Produces content using engineered prompts
    â€¢ Cleans and formats output
    â†“
Download-Ready Content
```

### Project Structure

```
research_tool/
â”œâ”€â”€ config.py                  # Configuration & constants
â”œâ”€â”€ data_models.py             # Data structures (UserInput, EngineeredPrompt)
â”œâ”€â”€ api_client.py              # LLM API client (OpenRouter)
â”œâ”€â”€ utils.py                   # Utility functions
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ interface.py           # Streamlit UI components
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py          # Abstract base agent class
â”‚   â”œâ”€â”€ agent1_prompt.py       # Prompt Engineering Agent
â”‚   â””â”€â”€ agent2_research.py     # Research Generator Agent
â”œâ”€â”€ app.py                     # Application orchestrator
â”œâ”€â”€ main.py                    # Entry point
â”œâ”€â”€ .env                       # Environment variables (not in repo)
â”œâ”€â”€ template.json              # (Optional) Fallback prompt template
â””â”€â”€ README.md                  # This file
```

## âœ¨ Features

### Supported Content Types
- Research Papers
- Essays
- Blog Posts
- Technical Reports
- Literature Reviews
- Case Studies
- White Papers

### Writing Styles
- Academic
- Professional
- Conversational
- Technical
- Persuasive
- Analytical
- Descriptive

### Content Lengths
- Short (500 words)
- Medium (1000 words)
- Long (2000 words)
- Very Long (3000+ words)

### Additional Features
- **Smart Prompt Engineering**: Uses LLM to generate optimized prompts
- **Clean Output**: Automatically removes thinking tags and formatting artifacts
- **One-Click Download**: Export generated content as text files
- **Professional UI**: Clean, distraction-free user interface
- **Modular Architecture**: Easy to extend with new agents or features
- **Error Handling**: Graceful error messages and validation

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)
- OpenRouter API key (or compatible LLM API key)

### Installation

1. **Clone or download the project**
   ```bash
   git clone <repository-url>
   cd research_tool
   ```

2. **Create virtual environment (recommended)**
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Create `.env` file**
   ```bash
   echo "OPENROUTER_API_KEY=your_api_key_here" > .env
   ```

   Or manually create `.env`:
   ```
   OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxx
   ```

5. **Create `template.json` (optional fallback)**
   ```json
   {
       "input_variables": ["paper_input", "style_input", "length_input", "user_input"],
       "template": "Write a {paper_input} in {style_input} style about {user_input}. The output should be approximately {length_input} in length."
   }
   ```

### Quick Start

```bash
streamlit run main.py
```

The application will open in your default browser at `http://localhost:8501`

## ğŸ“– Usage

### Basic Workflow

1. **Open the application** and you'll see the Research Content Generator interface
2. **Fill in your requirements**:
   - Select paper format (Research Paper, Essay, etc.)
   - Choose writing style (Academic, Professional, etc.)
   - Pick desired length (Short, Medium, Long, Very Long)
   - Enter your research topic or question
3. **Click "Generate Research Content"** button
4. **Wait** for Agent 1 and Agent 2 to process (usually 10-30 seconds)
5. **Review** the generated content
6. **Download** as text file with one click

### Example Topics

- "The impact of machine learning on healthcare systems"
- "Sustainable energy solutions for developing nations"
- "Blockchain technology in supply chain management"
- "Artificial intelligence ethics and governance"
- "Remote work culture and employee productivity"

## ğŸ”§ Configuration

All configuration is centralized in `config.py`:

```python
class Config:
    # API Settings
    OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
    MODEL_NAME = "minimax/minimax-m2:free"
    
    # UI Settings
    PAGE_TITLE = "Research Tool"
    PAGE_ICON = "ğŸ“š"
    LAYOUT = "wide"
    
    # Content Options
    PAPER_FORMATS = [...]
    WRITING_STYLES = [...]
    LENGTH_OPTIONS = [...]
```

### Switching LLM Models

To use a different LLM (e.g., GPT-4, Claude):

1. Update `Config.MODEL_NAME` in `config.py`
2. Update API endpoint if necessary in `Config.OPENROUTER_BASE_URL`
3. Ensure your API key supports the new model

## ğŸ—ï¸ Module Documentation

### Core Modules

#### `config.py`
- Centralized configuration
- Model settings, UI constants, content options
- Single source of truth for all settings

#### `data_models.py`
- `UserInput`: Stores user preferences with validation
- `EngineeredPrompt`: Contains generated prompt and metadata
- Both use dataclass decorators for clean code

#### `api_client.py`
- `OpenRouterClient`: Handles LLM API calls
- Implements error handling and retry logic
- Returns raw output from API

#### `utils.py`
- `remove_think_tags()`: Cleans LLM reasoning tags from output
- `load_environment()`: Loads environment variables
- `get_api_key()`: Retrieves and validates API key
- `truncate_text()`: Truncates long strings for display

#### `ui/interface.py`
- `UIInterface`: Static class containing all UI components
- Methods for rendering forms, buttons, content, downloads
- Separation of UI logic from business logic

### Agent Modules

#### `agents/base_agent.py`
- `BaseAgent`: Abstract base class for all agents
- Forces implementation of `run()` method
- Provides common agent interface

#### `agents/agent1_prompt.py`
- `PromptEngineeringAgent`: Generates optimized prompts using LLM
- Takes `UserInput`, returns `EngineeredPrompt`
- Implements intelligent prompt generation

#### `agents/agent2_research.py`
- `ResearchGeneratorAgent`: Generates research content
- Takes `EngineeredPrompt`, returns cleaned content
- Implements output processing and formatting

### Application Module

#### `app.py`
- `ResearchToolApp`: Main orchestrator class
- Initializes all components
- Coordinates workflow between agents and UI
- Handles user interaction and error states

#### `main.py`
- Entry point for the application
- Creates and runs `ResearchToolApp`

## ğŸ” Security

### Best Practices

- **Never commit `.env` file** to version control
- **Use environment variables** for sensitive data
- **Validate user input** before processing
- **Handle API errors** gracefully
- **Limit API calls** to prevent abuse

### API Key Safety

```python
# Good - from environment
api_key = os.getenv("OPENROUTER_API_KEY")

# Bad - hardcoded
api_key = "sk-or-v1-xxxxx"  # DO NOT DO THIS
```

## ğŸ“¦ Dependencies

See `requirements.txt`:

```
streamlit>=1.28.0
openai>=1.0.0
langchain-core>=0.1.0
python-dotenv>=1.0.0
regex>=2023.0.0
```

### Why Each Dependency?

- **streamlit**: Web framework for creating the UI
- **openai**: SDK for LLM API calls
- **langchain-core**: Prompt template management
- **python-dotenv**: Environment variable management
- **regex**: Advanced text pattern matching (for tag removal)

## ğŸš¦ Error Handling

The application includes comprehensive error handling:

| Error | Cause | Solution |
|-------|-------|----------|
| API Key Not Found | Missing `.env` or env variable | Create `.env` with `OPENROUTER_API_KEY` |
| API Connection Failed | Network issue or invalid key | Check internet, verify API key validity |
| Template Load Failed | Missing or invalid `template.json` | Verify file exists and is valid JSON |
| Prompt Engineering Failed | LLM error or invalid input | Check input, review API logs |
| Content Generation Failed | LLM error or timeout | Try again, check API status |

## ğŸ”„ Workflow Example

```
Input: "Impact of AI on healthcare"
Format: Research Paper
Style: Academic
Length: Medium (1000 words)

â†“

Agent 1 generates optimized prompt:
"Write a comprehensive research paper in academic style 
about the impact of AI on healthcare systems. The paper 
should be approximately 1000 words and include introduction, 
methodology, findings, and conclusion. Use formal language 
and include relevant statistics and case studies..."

â†“

Agent 2 receives engineered prompt and generates:
"Title: The Impact of Artificial Intelligence on Modern Healthcare Systems

Introduction:
Artificial intelligence (AI) has emerged as a transformative 
technology in the healthcare industry, fundamentally changing 
how medical professionals diagnose, treat, and manage patient care...
[continues for ~1000 words]"

â†“

Output cleaned and formatted for download
```

## ğŸ¨ Customization

### Adding New Paper Formats

Edit `config.py`:
```python
PAPER_FORMATS = [
    'Research Paper',
    'Essay',
    'Your New Format',  # Add here
    # ...
]
```

### Adding New Writing Styles

Edit `config.py`:
```python
WRITING_STYLES = [
    'Academic',
    'Your New Style',  # Add here
    # ...
]
```

### Adding New Agent

1. Create `agents/agent3_example.py`:
```python
from agents.base_agent import BaseAgent

class ExampleAgent(BaseAgent):
    def __init__(self):
        super().__init__(name="ExampleAgent")
    
    def run(self, content):
        # Your logic here
        return processed_content
```

2. Initialize in `app.py`:
```python
self.example_agent = ExampleAgent()
```

3. Use in workflow:
```python
result = self.example_agent.run(previous_result)
```

## ğŸ“Š Performance

### Typical Timings

- **Prompt Engineering**: 2-5 seconds
- **Content Generation**: 15-45 seconds (depends on length)
- **Total**: 20-50 seconds per request

### Optimization Tips

- Use shorter content lengths for faster results
- Specific topics generate faster than vague ones
- Less complex writing styles may be faster

## ğŸ› Troubleshooting

### Application won't start
```bash
# Check Python version
python --version  # Should be 3.8+

# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### "API Key not found" error
```bash
# Verify .env file exists
ls -la .env

# Verify content
cat .env

# Should contain:
# OPENROUTER_API_KEY=your_key_here
```

### Slow content generation
- Check internet connection
- Verify API service status
- Try shorter content length
- Consider using faster model variant

### Output quality issues
- Try more specific topic descriptions
- Adjust writing style selection
- Increase content length for more detail
- Review and refine the generated prompt in logs

## ğŸ“ˆ Future Enhancements

Potential features for future versions:

- [ ] Fact-checking agent (Agent 3)
- [ ] Citation generator agent (Agent 4)
- [ ] Plagiarism detection agent
- [ ] Multi-language support
- [ ] Custom style templates
- [ ] Content variation generation
- [ ] Collaborative editing mode
- [ ] Cloud storage integration
- [ ] Batch processing for multiple topics
- [ ] Performance analytics and metrics

## ğŸ¤ Contributing

Contributions are welcome! To contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Make your changes
4. Commit (`git commit -m 'Add AmazingFeature'`)
5. Push to branch (`git push origin feature/AmazingFeature`)
6. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Support

For issues, questions, or suggestions:

- Open an issue on GitHub
- Check existing issues for solutions
- Review the troubleshooting section
- Check API service status

## ğŸ™ Acknowledgments

- Built with [Streamlit](https://streamlit.io/)
- Powered by [OpenRouter API](https://openrouter.ai/)
- Uses [LangChain](https://www.langchain.com/) for prompt management
- Inspired by best practices in prompt engineering and multi-agent systems

## ğŸ“ Changelog

### Version 1.0.0 (2025-10-28)
- Initial release
- Two-agent architecture (Prompt Engineering + Content Generation)
- Support for 7 paper formats and 7 writing styles
- Clean, user-focused interface
- Modular, extensible codebase

---

**Made with â¤ï¸ by [Your Name/Team]**

For the latest updates and information, visit the [project repository](https://github.com/yourusername/research-tool)
# Research-Agent
